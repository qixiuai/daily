from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import numpy as np
import pandas as pd

from glob import glob

import physionetchallenge2018_lib as phyc_lib

from sklearn.model_selection import train_test_split

from tensor2tensor.utils import metrics
from tensor2tensor.utils import registry
from tensor2tensor.layers import modalities
from tensor2tensor.data_generators import problem
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.data_generators import generator_utils

import tensorflow as tf
tf.enable_eager_execution()

import pdb

flags = tf.flags
FLAGS = flags.FLAGS

flags.DEFINE_string("phyc_data_dir",
                    "/home/guo/t2tstage/resources/starter/training",
                    "phyc data directory")

class PhycProblem(problem.Problem):

    @property
    def name(self):
        return "phyc_problem"
    
    def feature_encoders(self, data_dir):
        del data_dir
        return {
            "inputs": text_encoder.RealEncoder(),
            "targets": text_encoder.ClassLabelEncoder(self.class_labels),
        }

    @property
    def dataset_splits(self):
        return [{
            "split": problem.DatasetSplit.TRAIN,
            "shards": self.num_train_shards,
        }, {
            "split": problem.DatasetSplit.EVAL,
            "shards": self.num_eval_shards,
        }, {
            "split": problem.DatasetSplit.TEST,
            "shards": self.num_test_shards,
        }]

    @property
    def num_classes(self):
        raise NotImplementedError()
    
    @property
    def num_train_shards(self):
        return 2

    @property
    def num_eval_shards(self):
        return 1

    @property
    def num_test_shards(self):
        return 1

    def eval_metrics(self):
        eval_metrics = [
            metrics.Metrics.ACC,
        ]
        return eval_metrics

    def preprocess_example(self, example, unused_mode, unused_hparams):
        raise NotImplementedError()
    
    def generate_samples(self, data_dir, tmp_dir, dataset_split):
        if dataset_split == problem.DatasetSplit.TRAIN:
            return phyc_generator(True)
        if dataset_split == problem.DatasetSplit.EVAL:
            return phyc_generator(False)
        

    def hparams(self, defaults, unused_model_hparams):
        p = defaults
        p.modality = {"inputs": modalities.IdentityModality,
                      "targets": modalities.ClassLabelModality}
        p.vocab_size = {"inputs": 1000, "targets": self.num_classes}
        p.input_space_id = problem.SpaceID.REAL
        p.target_space_id = problem.SpaceID.IMAGE_LABEL
        
    def generate_data(self, data_dir, tmp_dir, task_id=-1):
        filepath_fns = {
            problem.DatasetSplit.TRAIN: self.training_filepaths,
            problem.DatasetSplit.EVAL: self.dev_filepaths,
            problem.DatasetSplit.TEST: self.test_filepaths,
        }

        split_paths = [(split["split"], filepath_fns[split["split"]](
            data_dir, split["shards"], shuffled=False))
                       for split in self.dataset_splits]
        
        all_paths = []
        for _, paths in split_paths:
            all_paths.extend(paths)

        for split, paths in split_paths:
            generator_utils.generate_files(
                self.generate_samples(data_dir, tmp_dir, split), paths)

        generator_utils.shuffle_dataset(all_paths)

    def example_reading_spec(self):
        data_fields = {
            "inputs": tf.FixedLenFeature((self.width, 1, self.num_signals),
                                         tf.float32),
            "targets": tf.FixedLenFeature((1,), tf.int64),
        }
        data_items_to_decoders = {}
        data_items_to_decoders["inputs"] = tf.contrib.slim.tfexample_decoder.Tensor("inputs")
        data_items_to_decoders["targets"] = tf.contrib.slim.tfexample_decoder.Tensor("targets")
        return (data_fields, data_items_to_decoders)


def record_generator(record_name):
    anno_file    = record_name + ".arousal"
    header_file  = record_name + ".hea"
    signal_file  = record_name + ".mat"
    arousal_file = record_name + "-arousal.mat"
    
    signal_names, Fs, n_samples = phyc_lib.import_signal_names(header_file)
    signal_names = list(np.append(signal_names, "arousals"))

    this_data = phyc_lib.get_subject_data(anno_file, arousal_file, signal_file, signal_names)

    signals = this_data.get(["C3-M2", "C4-M1", "E1-M2", "ABD", "SaO2"]).values
    arousals = this_data.get(["arousals"]).values
    
    window_size = Fs * 60 # 60 second
    for ind in range(len(arousals)):
        yield {
            "inputs": signals[ind : ind + window_size],
            "targets": arousals[ind : ind + window_size],
        }
    
def phyc_generator(is_training):
    subjects = os.listdir(FLAGS.phyc_data_dir)[:10]
    train_subjects, test_subjects = train_test_split(subjects, test_size=0.2)
    subject_names = train_subjects if is_training else test_subjects
    for subject_name in subject_names:
        subject_path = os.path.join(FLAGS.phyc_data_dir, subject_name, subject_name)
        for example in record_generator(subject_path):
            yield example

def main(unused_args):
    del unused_args
    prob = PhycProblem()
    data_dir = "/home/guo/t2t/phyc/data/"
    prob.generate_data(data_dir, "")
    dataset = prob.dataset()
    for example in dataset:
        pass
    
if __name__ == '__main__':
    tf.app.run(main)
