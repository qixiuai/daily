
import os
import pdb
import numpy as np
from absl import app as absl_app
from absl import flags
from absl import logging
from sklearn.metrics import confusion_matrix

import tensorflow as tf
from tensorflow.python.util import object_identity

from pai import data_pipeline
from pai.utils.callbacks import get_callbacks
from official.transformer.v2 import metrics
from official.transformer.v2 import misc
from official.transformer.v2 import optimizer
from official.transformer.v2 import transformer
from official.transformer.v2 import translate
from official.utils.flags import core as flags_core
from official.utils.logs import logger
from official.utils.misc import keras_utils
from official.utils.misc import distribution_utils

from models import base_model


INF = int(1e9)
_SINGLE_SAMPLE = 1


def evaluate_stage_accuracy(model, params, distribution_strategy=None):
    pass


class PaiTask(object):

    def __init__(self, flags_obj):
        self.flags_obj = flags_obj
        self.predict_model = None
        num_gpus = flags_core.get_num_gpus(flags_obj)
        self.params = params = misc.get_model_params(flags_obj.param_set, num_gpus)
        params["dataset"] = "ecg"
        params["num_gpus"] = num_gpus
        params["data_dir"] = flags_obj.data_dir
        params["model_dir"] = flags_obj.model_dir
        params["num_parallel_calls"] = (
            flags_obj.num_parallel_calls or tf.data.experimental.AUTOTUNE)
        params["batch_size"] = flags_obj.batch_size or params["default_batch_size"]
        params["repeat_dataset"] = None
        params["dtype"] = flags_core.get_tf_dtype(flags_obj)
        params["enable_metrics_in_training"] = flags_obj.enable_metrics_in_training

        if params["dtype"] == tf.float16:
            policy = tf.keras.mixed_precision.experimental.Policy("infer_float32_vars")
            tf.keras.mixed_precision.experimental.set_policy(policy)

        self.distribution_strategy = distribution_utils.get_distribution_strategy(
            distribution_strategy=flags_obj.distribution_strategy,
            num_gpus=num_gpus,
            tpu_address=flags_obj.tpu or "")

        logging.info("Runing PAI with num_gpus = {}".format(num_gpus))

        """
        if self.use_tpu:
            pass
        if self.distribution_strategy:
            logging.info("For training, using distribution strategy: {}".format(self.distribution_strategy))
        else:
            logging.info("Not using any distribution strategy.")
        """

    @property
    def use_tpu(self):
        if self.distribution_strategy:
            return isinstance(self.distribution_strategy, tf.distribute.experimental.TPUStrategy)
        return False

    def train(self):
        logging.debug("Running PAI with train mode")
        params = self.params
        flags_obj = self.flags_obj
        keras_utils.set_session_config(enable_xla=flags_obj.enable_xla)
        _ensure_dir(flags_obj.model_dir)
        with distribution_utils.get_strategy_scope(self.distribution_strategy):
            #model = transformer.create_model(params, is_train=True)
            model = base_model.create_model(params, is_train=True)
            opt = self._create_optimizer()

            current_step = 0
            checkpoint = tf.train.Checkpoint(model=model, optimizer=opt)
            latest_checkpoint = tf.train.latest_checkpoint(flags_obj.model_dir)
            if latest_checkpoint:
                checkpoint.restore(latest_checkpoint)
                logging.info("Loaded checkpoint %s", latest_checkpoint)
                current_step = opt.iterations.numpy()

            model.compile(opt)
        #model.summary()
        train_ds = data_pipeline.train_input_fn(params)
        valid_ds = data_pipeline.eval_input_fn(self.params)
        callbacks = self._create_callbacks(flags_obj.model_dir, 0, params)

        if flags_obj.train_steps < flags_obj.steps_between_evals:
            flags_obj.steps_between_evals = flags_obj.train_steps
        history = None
        while current_step < flags_obj.train_steps:
            remaining_steps = flags_obj.train_steps - current_step
            train_steps_per_eval = (remaining_steps if remaining_steps < flags_obj.steps_between_evals
                                    else flags_obj.steps_between_evals)
            current_iteration = current_step // flags_obj.steps_between_evals

            logging.info("Start train iteration at global step:{}".format(current_step))
            history = model.fit(
                train_ds,
                validation_data=valid_ds,
                initial_epoch=current_iteration,
                epochs=current_iteration + 1,
                steps_per_epoch=flags_obj.steps_between_evals,
                callbacks=callbacks,
                verbose=(2 if flags_obj.enable_time_history else 1))
            current_step += train_steps_per_eval
            #logging.info("Train history: {}".format(history.history))
        logging.info("End train iteration at global step:{}".format(current_step))
        return history

    def eval(self):
        logging.info("run eval mode")
        with distribution_utils.get_strategy_scope(self.distribution_strategy):
            if not self.predict_model:
                model = base_model.create_model(self.params, is_train=False)
                self.predict_model = model
            self._load_weights_if_possible(
                self.predict_model,
                tf.train.latest_checkpoint(self.flags_obj.model_dir))
            #self.predict_model.summary()
            ds = data_pipeline.eval_input_fn(self.params)
            #predicts = self.predict_model.predict(ds, verbose=1)
            pred = None
            targets = []
            preds = []
            for inputs in ds:
                x, y = inputs[0]
                pred = self.predict_model(x)
                pred = np.argmax(pred.numpy(), axis=1)
                targets.append(y)
                preds.append(pred)
            targets = np.asarray(targets).flatten()
            preds = np.asarray(preds).flatten()
            acc = np.sum(targets == preds) / len(preds)
            mat = confusion_matrix(targets, preds)
            print(mat)
            print("acc: {}", acc)
            return acc

    def predict(self):
        logging.debug("run predict")
        params = self.params
        with tf.name_scope("model"):
            model = base_model.create_model(params, is_train=False)
            self._load_weights_if_possible(model, tf.train.latest_checkpoint(self.flags_obj.model_dir))
            model.summary()
        ds = data_pipeline.eval_input_fn(params)
        ret = model.predict(ds)
        return ret

    def _create_callbacks(self, cur_log_dir, init_steps, params):
        sfunc = optimizer.LearningRateFn(params["learning_rate"],
                                         params["hidden_size"],
                                         params["learning_rate_warmup_steps"])
        callbacks = get_callbacks()
        scheduler_callback = optimizer.LearningRateScheduler(sfunc, init_steps)
        callbacks.append(scheduler_callback)
        ckpt_full_path = os.path.join(cur_log_dir, "cp-{epoch:04d}.ckpt")
        callbacks.append(tf.keras.callbacks.ModelCheckpoint(ckpt_full_path,
                                                            save_weights_only=True))
        return callbacks

    def _load_weights_if_possible(self, model, init_weight_path=None):
        if init_weight_path:
            logging.info("Load weight: {}".format(init_weight_path))
            if False:
                checkpoint = tf.train.Checkpoint(
                    model=model, optimizer=self._create_optimizer())
                checkpoint.restore(init_weight_path)
            else:
                model.load_weights(init_weight_path)
        else:
            print("Weights not loaded from path:{}".format(init_weight_path))

    def _create_optimizer(self):
        params = self.params
        """
        lr_schedule = optimizer.LearningRateSchedule(
            params["learning_rate"], params["hidden_size"],
            params["learning_rate_warmup_steps"])
        opt = tf.keras.optimizer.Adam(
            lr_schedule if self.use_tpu else params["learning_rate"],
            params["optimizer_adam_beta1"],
            params["optimizer_adam_beta2"],
            epsilon=params["optimizer_adam_epsilon"])
        """        
        opt = tf.keras.optimizers.Adam(
            params["learning_rate"],
            params["optimizer_adam_beta1"],
            params["optimizer_adam_beta2"],
            epsilon=params["optimizer_adam_epsilon"])
        if params["dtype"] == tf.float16:
            opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(
                opt, loss_scale=flags_core.get_loss_scale(self.flags_obj,
                                                          default_for_fp16="dynamic"))
        return opt


def _ensure_dir(log_dir):
    if not tf.io.gfile.exists(log_dir):
        tf.io.gfile.makedirs(log_dir)


def main(_):
    flags_obj = flags.FLAGS
    with logger.benchmark_context(flags_obj):
        task = PaiTask(flags_obj)
        def _run_task(task):
            if flags_obj.mode == "train":
                task.train()
            elif flags_obj.mode == "predict":
                task.predict()
            elif flags_obj.mode == "eval":
                task.eval()
            else:
                raise ValueError("Invalid mode {}".format(flags_obj.mode))

        logging.debug("distribution strategy: {}".format(flags_obj.distribution_strategy))
        if flags_obj.distribution_strategy != "tpu":
            _run_task(task)
        else:
            primary_cpu_task = ("/job:worker"
                                if flags_obj.use_tpu_2vm_config is not None else "")
            with tf.device(primary_cpu_task):
                _run_task(task)


if __name__ == "__main__":
    logging.set_verbosity(logging.DEBUG)
    misc.define_transformer_flags()
    absl_app.run(main)
