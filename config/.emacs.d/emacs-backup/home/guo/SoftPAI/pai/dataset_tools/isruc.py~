""" ISRUC dataset """

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import pdb
import pysnooper
import glob
import time
import random
import pickle
import shutil
import numpy as np
import matplotlib.pyplot as plt

from scipy.io import loadmat
#from dataset import Balancer
from tqdm import tqdm

random.seed(2019)
np.random.seed(2019)


class Balancer(object):

    def __init__(self):
        self._label_counts = {}
        self._samples = set()
        
    def calc_weight(self, x, y):
        sample_id = hash(tuple(x[0,:,0]))
        key = tuple(y)
        if sample_id not in self._samples:
            self._samples.add(sample_id)
            if key in self._label_counts:
                self._label_counts[key] += 1
            else:
                self._label_counts[key] = 1
        count = self._label_counts[key]
        weight = 1 / (1 + np.log10(count))
        return weight

def _mat2labelpath(matpath):
    subject_id = os.path.basename(matpath)[7:-4]
    dirname = os.path.dirname(matpath)
    dirname = dirname.replace("Extractedchannels", "")
    dirname = dirname.replace("ExtractedChannels", "")
    dirname = dirname.replace("-", "")
    # ...subgroup1/1/1_1.txt
    labelpath = dirname + "/" + str(subject_id) + "/" + str(subject_id) + "_1.txt"
    if "subgroupII" in dirname and "subgroupIII" not in dirname:
        session_id = matpath[-14:-13]
        dirname = "/home/guo/physio/database/isruc/subgroupII/"
        labelpath = dirname + "/" + str(subject_id) + "/" + str(session_id) + '/' + str(session_id) + "_1.txt"
    return labelpath


class RawIsruc(object):

    def __init__(self,
                 mode="train",
                 channels=["C3_A2", "O1_A2", "LOC_A2", "ROC_A1", "X1"],
                 class_balanced=False,
                 step=16):
        self.mode = mode
        self.channels = channels
        self.class_balanced = class_balanced
        self.step = step
        isruc_dir = "/home/guo/physio/database/isruc/ExtractedChannels/"
        self.mat_files = glob.glob(isruc_dir + "**/**.mat", recursive=True)
        self.generate_dataset()
        self._have_caches = False
        self._balancer = Balancer()
        self._caches = {}
        
    def _load_labels(self, matpath):
        labelpath = _mat2labelpath(matpath)
        label = np.loadtxt(labelpath, dtype=np.int64)
        label = label[:-30]
        labelpath2 = labelpath.split("_")
        labelpath2[-1] = "2.txt"
        labelpath2 = "_".join(labelpath2)
        label2 = np.loadtxt(labelpath2, dtype=np.int64)
        label2 = label2[:-30]
        return label, label2

    def load_subject(self, file_path, channels):
        """ return (num_epochs, 6000, num_channels) """
        #print(self.mode + "--" + file_path, flush=True, end="\n")
        raw_dict = loadmat(file_path, variable_names=channels)
        data = np.stack([raw_dict[c] for c in channels], axis=2)
        #data = [raw_dict[c] for c in channels]
        labels1, labels2 = self._load_labels(file_path)
        labels = labels1
        for ind, label in enumerate(labels1):
            if label == 5:
                labels1[ind] = 4
        for ind, label in enumerate(labels2):
            if label == 5:
                labels2[ind] = 4
        if not self.class_balanced:
            return (data, labels1, labels2)
        if self.class_balanced:
            raise ValueError("class balanced in isruc is not supported")
        print(np.asarray([np.sum(labels == i) for i in range(5)]) / len(labels))
        n_per_stage = np.min([np.sum(labels == i) for i in range(5)])
        dataset = [(data[labels==l], labels[labels==l]) for l in range(5)]
        dataset_balanced = []
        for X, y in dataset:
            idx = np.random.choice(len(y), size=n_per_stage, replace=True)
            dataset_balanced.append((X[idx],y[idx]))
        data = np.concatenate([X for X, y in dataset_balanced])
        labels = np.concatenate([y for X, y in dataset_balanced])
        n = len(labels)
        idx = np.arange(n)
        np.random.shuffle(idx)
        data = data[idx]
        labels = labels[idx]
        #print([np.sum(labels == i) for i in range(5)])
        #pdb.set_trace()
        return (data,labels)

    def generate_dataset(self, seed=2018):
        random.seed(seed)
        mat_files = self.mat_files
        random.shuffle(mat_files)
        num_files = len(mat_files)
        num_train = int(num_files * 0.6)
        num_val = int(num_files * 0.2)
        num_test = int(num_files * 0.2)
        train_files = mat_files[:num_train]
        val_files = mat_files[num_train:num_train+num_val]
        test_files = mat_files[-num_test:]
        if self.mode == "train":
            self.mat_files = train_files
        elif self.mode == "validation":
            self.mat_files = val_files
        elif self.mode == "test":
            self.mat_files = test_files
        else:
            raise Exception("unexpected mode")
        random.shuffle(self.mat_files)

    def __call__(self):
        step = self.step
        for subject_file in tqdm(self.mat_files[:4]):
            if subject_file in self._caches:
                data, labels1, labels2 = self._caches[subject_file]
            else:
                data, labels1, labels2 = self.load_subject(subject_file, self.channels)
                self._caches[subject_file] = (data, labels1, labels2)
            yield (data, labels1, labels2, subject_file)
            """
            num_epochs = data.shape[0]
            for ind in range(0, num_epochs-step, step):
                x = data[ind:ind+step]
                y1 = labels1[ind:ind+step]
                y2 = labels2[ind:ind+step]
                #sample_weight = self._balancer.calc_weight(x, y)
                yield (x, y1, y2, subject_file, ind)
            """

if __name__ == '__main__':
    isruc = RawIsruc()
    for example, label in isruc():
        print(example.shape, label)
    for example, label in isruc():
        print(example.shape, label)


