
import os
import tensorflow as tf

from absl import logging
from absl import app as absl_app

from plotly.offline import plot
import plotly.graph_objs as go

import sys
sys.path.append("/home/guo/ECGTianchi/dataset")
from ecg import ECG

_READ_RECORD_BUFFER = 8 * 1000 * 1000

def _make_sequence_examples(inputs, step=1):
    #epochs = tf.shape(inputs["labels"])[0]
    epochs = inputs["epochs"]
    dataset = tf.data.Dataset.range(0, epochs, step)
    def _make_sequence_example(index):
        example = {}
        for key, val in inputs.items():
            #example[key] = val[index:index+step]
            if key == "epochs":
                continue
            example[key] = val[index]
        return ((tf.concat([example["C3_M2"], example["E1_M2"], example["EMG"]], axis=-1), example["labels"]),example["labels"])
        #return ((example["C3_M2"], example["labels"]), example["labels"])
    dataset = dataset.map(_make_sequence_example)
    return dataset

def _parse_tf_example(serialized_example):
    data_fields = {
        "C3_M2": tf.io.FixedLenSequenceFeature((6000,1), tf.float32, allow_missing=True),
        "E1_M2": tf.io.FixedLenSequenceFeature((6000,1), tf.float32, allow_missing=True),
        "EMG": tf.io.FixedLenSequenceFeature((6000,1), tf.float32, allow_missing=True),
        "labels": tf.io.FixedLenSequenceFeature((1,), tf.int64, allow_missing=True),
        "epochs": tf.io.FixedLenFeature([], tf.int64),
    }
    parsed = tf.io.parse_single_example(serialized_example, data_fields)
    return parsed


def _load_records(filename):
    return tf.data.TFRecordDataset(filename, buffer_size=_READ_RECORD_BUFFER)

def _read_and_batch_from_files(
        file_pattern, batch_size, num_parallel_calls, shuffle, mode, repeat=None,
        ctx=None):
    dataset = tf.data.Dataset.list_files(file_pattern, shuffle=shuffle)
    
    if ctx and ctx.num_input_pipelines > 1:
        logging.info("Shard %d of the dataset.", ctx.input_pipeline_id)
        dataset = dataset.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)

    options = tf.data.Options()
    options.experimental_deterministic = False
    dataset = dataset.interleave(
        _load_records,
        cycle_length=num_parallel_calls,
        block_length=1,
        num_parallel_calls=tf.data.experimental.AUTOTUNE).with_options(options)

    dataset = dataset.map(_parse_tf_example, num_parallel_calls=num_parallel_calls)
    dataset = dataset.interleave(
        _make_sequence_examples,
        cycle_length=num_parallel_calls,
        block_length=1,
        num_parallel_calls=tf.data.experimental.AUTOTUNE).with_options(options)
    if mode == "train":
        dataset = dataset.batch(batch_size, drop_remainder=True).repeat(repeat)
    else:
        dataset = dataset.batch(batch_size, drop_remainder=True)
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset

def train_input_fn_a(params, ctx=None):
    batch_size = params["batch_size"]
    repeat=params["repeat_dataset"]
    dataset = tf.data.Dataset.from_generator(
        ECG(mode="train"),
        output_types=((tf.float32, tf.float32, tf.float32), tf.float32),
        output_shapes=(((5000, 12), (3,), (55,)), (55,)),
    )
    dataset = dataset.batch(batch_size, drop_remainder=True).repeat(repeat)
    return dataset

def eval_input_fn_a(params, ctx=None):
    batch_size = params["batch_size"]
    repeat=params["repeat_datase"]
    dataset = tf.data.Dataset.from_generator(
        ECG(mode="minival"),
        output_types=((tf.float32, tf.float32, tf.int64), tf.int64),
        output_shapes=(((5000, 12), (3,), (55,)), (55,)),
    )
    dataset = dataset.batch(batch_size, drop_remainder=True)
    return dataset

def train_input_fn(params, ctx=None):
    dataset = params.get("dataset", "")
    if dataset == "ecg":
        return train_input_fn_a(params, ctx)
    file_pattern = os.path.join(params["data_dir"] or "", "*train*")
    return _read_and_batch_from_files(
        file_pattern, params["batch_size"],
        params["num_parallel_calls"],
        repeat=params["repeat_dataset"],
        mode="train",
        shuffle=True,  ctx=ctx,
    )

def eval_input_fn(params):
    dataset = params.get("dataset", "")
    if dataset == "ecg":
        return eval_input_fn_a(params)
    file_pattern = os.path.join(params["data_dir"] or "", "*valid*")
    return _read_and_batch_from_files(
        file_pattern, params["batch_size"],
        params["num_parallel_calls"],
        mode="eval",
        shuffle=True)


def main(_):
    data_dir = "/home/guo/physio/dl/tfrecords/isruc.tfrecords"
    params = {}
    params["data_dir"] = data_dir
    params["batch_size"] = 64
    params["num_parallel_calls"] = 12
    params["repeat_dataset"] = 1
    dataset = train_input_fn(params)
    for input in dataset:
        (x, y) = input
        print(x.shape,y.shape)


if __name__ == "__main__":
    absl_app.run(main)
