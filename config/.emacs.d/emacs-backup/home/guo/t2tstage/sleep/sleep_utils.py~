from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import numpy as np
import pandas as pd

from glob import glob

from tensor2tensor.utils import metrics
from tensor2tensor.utils import registry
from tensor2tensor.layers import modalities
from tensor2tensor.data_generators import problem
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.data_generators import generator_utils

from stage.modalities import ClassLabelStageModality

import tensorflow as tf

class StageProblem(problem.Problem):

    @property
    def class_labels(self):
        return [i for i in [0, 1, 2, 3, 5]]
    
    def feature_encoders(self, data_dir):
        del data_dir
        return {
            "inputs": text_encoder.RealEncoder(),
            "targets": text_encoder.ClassLabelEncoder(self.class_labels),
        }

    @property
    def dataset_splits(self):
        return [{
            "split": problem.DatasetSplit.TRAIN,
            "shards": self.num_train_shards,
        }, {
            "split": problem.DatasetSplit.EVAL,
            "shards": self.num_eval_shards,
        }, {
            "split": problem.DatasetSplit.TEST,
            "shards": self.num_test_shards,
        }]
    
    @property
    def num_train_shards(self):
        return 2

    @property
    def num_eval_shards(self):
        return 1

    @property
    def num_test_shards(self):
        return 1

    @property
    def num_signals(self):
        raise NotImplementedError()

    @property
    def num_stages(self):
        return len(self.class_labels)

    @property
    def num_classes(self):
        return len(self.class_labels)
    
    @property
    def width(self):
        return 30*200

    def eval_metrics(self):
        eval_metrics = [
            metrics.Metrics.ACC,
        ]
        return eval_metrics

    def preprocess_example(self, example, unused_mode, unused_hparams):
        flat_inputs = example["inputs"]
        example["inputs"] = tf.reshape(
            flat_inputs, [self.width, self.num_signals, 1])
        return example
    
    def generate_samples(self, data_dir, tmp_dir, dataset_split):
        raise NotImplementedError()

    def hparams(self, defaults, unused_model_hparams):
        p = defaults
        p.modality = {"inputs": modalities.IdentityModality,
                      "targets": ClassLabelStageModality}
        p.vocab_size = {"inputs": 1000, "targets": self.num_stages}
        p.input_space_id = problem.SpaceID.REAL
        p.target_space_id = problem.SpaceID.IMAGE_LABEL
        
    def generate_data(self, data_dir, tmp_dir, task_id=-1):
        filepath_fns = {
            problem.DatasetSplit.TRAIN: self.training_filepaths,
            problem.DatasetSplit.EVAL: self.dev_filepaths,
            problem.DatasetSplit.TEST: self.test_filepaths,
        }

        split_paths = [(split["split"], filepath_fns[split["split"]](
            data_dir, split["shards"], shuffled=False))
                       for split in self.dataset_splits]
        
        all_paths = []
        for _, paths in split_paths:
            all_paths.extend(paths)

        for split, paths in split_paths:
            generator_utils.generate_files(
                self.generate_samples(data_dir, tmp_dir, split), paths)

        generator_utils.shuffle_dataset(all_paths)
        
    def example_reading_spec(self):
        data_fields = {
            "inputs": tf.FixedLenFeature((self.width, 1, self.num_signals),
                                         tf.float32),
            "targets": tf.FixedLenFeature((1,), tf.int64),
        }
        data_items_to_decoders = {}
        data_items_to_decoders["inputs"] = tf.contrib.slim.tfexample_decoder.Tensor("inputs")
        data_items_to_decoders["targets"] = tf.contrib.slim.tfexample_decoder.Tensor("targets")
        return (data_fields, data_items_to_decoders)
    
