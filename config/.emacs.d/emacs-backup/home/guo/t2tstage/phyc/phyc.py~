from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import numpy as np
import pandas as pd

from glob import glob

from tensor2tensor.utils import metrics
from tensor2tensor.utils import registry
from tensor2tensor.layers import modalities
from tensor2tensor.data_generators import problem
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.data_generators import generator_utils

import tensorflow as tf
tf.enable_eager_execution()

flags = tf.flags
FLAGS = flags.FLAGS

flags.DEFINE_string("phyc_data_dir",
                    "/home/guo/t2tstage/resources/starter/training",
                    "phyc data directory")

class PhycProblem(problem.Problem):
    
    def feature_encoders(self, data_dir):
        del data_dir
        return {
            "inputs": text_encoder.RealEncoder(),
            "targets": text_encoder.ClassLabelEncoder(self.class_labels),
        }

    @property
    def dataset_splits(self):
        return [{
            "split": problem.DatasetSplit.TRAIN,
            "shards": self.num_train_shards,
        }, {
            "split": problem.DatasetSplit.EVAL,
            "shards": self.num_eval_shards,
        }, {
            "split": problem.DatasetSplit.TEST,
            "shards": self.num_test_shards,
        }]

    @property
    def num_classes(self):
        raise NotImplementedError()
    
    @property
    def num_train_shards(self):
        return 2

    @property
    def num_eval_shards(self):
        return 1

    @property
    def num_test_shards(self):
        return 1

    def eval_metrics(self):
        eval_metrics = [
            metrics.Metrics.ACC,
        ]
        return eval_metrics

    def preprocess_example(self, example, unused_mode, unused_hparams):
        raise NotImplementedError()
    
    def generate_samples(self, data_dir, tmp_dir, dataset_split):
        raise NotImplementedError()

    def hparams(self, defaults, unused_model_hparams):
        p = defaults
        p.modality = {"inputs": modalities.IdentityModality,
                      "targets": modalities.ClassLabelModality}
        p.vocab_size = {"inputs": 1000, "targets": self.num_classes}
        p.input_space_id = problem.SpaceID.REAL
        p.target_space_id = problem.SpaceID.IMAGE_LABEL
        
    def generate_data(self, data_dir, tmp_dir, task_id=-1):
        filepath_fns = {
            problem.DatasetSplit.TRAIN: self.training_filepaths,
            problem.DatasetSplit.EVAL: self.dev_filepaths,
            problem.DatasetSplit.TEST: self.test_filepaths,
        }

        split_paths = [(split["split"], filepath_fns[split["split"]](
            data_dir, split["shards"], shuffled=False))
                       for split in self.dataset_splits]
        
        all_paths = []
        for _, paths in split_paths:
            all_paths.extend(paths)

        for split, paths in split_paths:
            generator_utils.generate_files(
                self.generate_samples(data_dir, tmp_dir, split), paths)

        generator_utils.shuffle_dataset(all_paths)
        
    def example_reading_spec(self):
        data_fields = {
            "inputs": tf.FixedLenFeature((self.width, 1, self.num_signals),
                                         tf.float32),
            "targets": tf.FixedLenFeature((1,), tf.int64),
        }
        data_items_to_decoders = {}
        data_items_to_decoders["inputs"] = tf.contrib.slim.tfexample_decoder.Tensor("inputs")
        data_items_to_decoders["targets"] = tf.contrib.slim.tfexample_decoder.Tensor("targets")
        return (data_fields, data_items_to_decoders)
    

def phyc_generator():
    print(FLAGS.phyc_data_dir)
    
def main(unused_args):
    del unused_args
    
    prob = PhycProblem()
    prob.generate_data("", "")

    dataset = prob.dataset()
    for example in dataset:
        pass
    
if __name__ == '__main__':
    tf.app.run(main)
