
import pdb
import numpy as np
import tensorflow as tf

from sklearn.metrics import confusion_matrix
from tensorflow.python.keras.metrics import MeanMetricWrapper
from tensorflow.python.eager import context


def eval_confusion_matrix(dataset, model):
    targets = []
    preds = []
    for batch_id, (input, target) in enumerate(dataset):
        pred = model(input)
        targets.extend(target.numpy().tolist())
        preds.extend(np.argmax(pred.numpy(), axis=1).tolist())
        tf.print(batch_id)
    mat = confusion_matrix(targets, preds)
    tf.print(mat)
    wake_acc = mat[0,0] / np.sum(mat[0,:])
    n1_acc = mat[1,1] / np.sum(mat[1,:])
    n2_acc = mat[2,2] / np.sum(mat[2,:])
    n3_acc = mat[3,3] / np.sum(mat[3,:])
    rem_acc = mat[4,4] / np.sum(mat[4,:])
    arr = [wake_acc, n1_acc, n2_acc, n3_acc, rem_acc]

    label2id = {"wake":0, "N1": 1, "N2":2, "N3":3, "REM":4}
    id2label = {0:"wake", 1:"N1", 2:"N2", 3:"N3", 4:"REM"}
    acc_count = 0
    for i in range(5):
        acc_count += mat[i,i]
    acc = acc_count / np.sum(mat)
    print("total acc: {}".format(acc))
    print("recall")
    for id in range(5):
        label = id2label[id]
        acc = mat[id,id] / np.sum(mat[id,:])
        print("{} recall: {}".format(label, acc))
    print("precision")
    for id in range(5):
        label = id2label[id]
        acc = mat[id,id] / np.sum(mat[:, id])
        print("{} precision: {}".format(label, acc))


@tf.function
def confusion_matrix_accuracy(y_true, y_pred):
    tf.print(y_true)
    tf.print(y_pred)
    print(y_true.device)
    y_true = tf.math.argmax(y_true, axis=1)
    y_pred = y_pred
    #mat = confusion_matrix(y_true, y_pred)
    #wake_acc = mat[0,0] / np.sum(mat[0,:])
    #n1_acc = mat[1,1] / np.sum(mat[1,:])
    #n2_acc = mat[2,2] / np.sum(mat[2,:])
    #n3_acc = mat[3,3] / np.sum(mat[3,:])
    #rem_acc = mat[4,4] / np.sum(mat[4,:])
    #arr = [wake_acc, n1_acc, n2_acc, n3_acc, rem_acc]
    #return np.asarray(arr), mat
    return mat

"""
def confusion_matrix_accuracy(y_true, y_pred):
    mat = np.zeros(5,5)
    y = np.argmax(y_pred)
    mat[y_true, y] += 1
    tf.print(mat.shape)
    return mat
"""

class ConfusionMatrixAccuracy(MeanMetricWrapper):

    def __init__(self, name="confusion_matrix_accuracy", dtype=None, **kwargs):
        super(ConfusionMatrixAccuracy, self).__init__(confusion_matrix_accuracy, name, dtype=dtype, **kwargs)
        self.mat = np.zeros((5,5), dtype=np.float64)
        #self.accuracies = np.zeros(5, dtype=np.float64)
        #self.count = 0.0

    def __call__(self, *args, **kwargs):
        self.update_state(*args, **kwargs)
        result = self.result()
        return result
        
    def update_state(self, y_true, y_pred, sample_weight=None):
        #assert(context.executing_eagerly())
        mat = confusion_matrix_accuracy(y_true, y_pred)
        tf.print(self.mat)
        self.mat += mat
        #self.accuracies = (self.accuracies * self.count + acc) / (self.count + 1)
        #self.accuracies = acc
        #self.count += 1
        
    def reset_states(self):
        self.mat = np.zeros((5,5))
        #self.accuracies = np.zeros(5)
        #self.count = 0
        
    def result(self):
        #return self.mat, self.accuracies,
        return self.mat


