
import tensorflow as tf


class BaseModel(tf.Module):

    def __init__(self):
        super(BaseModel, self).__init__()

    def build(self, input_shape):
        pass

    def __call__(self, inputs):
        return inputs

def image_preprocess(image, bgr=False):
    pass

    
class GeneralizedRCNN(tf.Module):

    def preprocess(self, image):
        image = tf.expand_dims(image, 0)
        image = image_preprocess(image, bgr=True)
        return tf.transpose(image, [0, 3, 1, 2])

    def __call__(self, inputs):
        image = self.preprocess(inputs["image/decoded"])
        features = self.backbone(image)
        anchor_inputs = {k: v for k, v in inputs.items() if k.startswith("anchor_")}
        
        proposals, rpn_losses = self.rpn(image, features, anchor_inputs)

        targets = [inputs[k] for k in ['gt_boxes', 'gt_labels']]
        fastercnn_head = self.roi_heads(image, features, proposals, targets)
        return pass


class ResNetC4Model(GeneralizedRCNN):

    def backbone(self, image):
        return [resnet_c4_backbone(image, resnet_num_blocks[:3])]
    
    def rpn(self, image, features, inputs):
        featuremap = features[0]
        rpn_label_logits, rpn_box_logits = rpn_head('rpn', featuremap, RPN_HEAD_DIM, RPN_NUM_ANCHOR)
        anchors = RPNAnchors(
            get_all_anchors(
                stride=rpn_anchor_stride, sizes=rpn_anchor_sizes,
                ratios=rpn_anchor_ratios, max_size=preproc_max_size),
            inputs["anchor_labels"], inputs["anchor_boxes"])
        anchors = anchors.narrow_to(featuremap)

        image_shape2d = tf.shape(image)[2:]
        pred_boxes_decoded = anchors.decode_logits(rpn_box_logits)
        proposal_boxes, proposal_scores = generate_rpn_proposals(
            tf.reshape(pred_boxes_decoded, [-1, 4]),
            tf.reshape(rpn_label_logits, [-1]),
            image_shape2d,
            TRAIN_PRE_NMS_TOPK or TEST_PRE_NMS_TOPK,
            TRAIN_POST_NMS_TOPK or TEST_POST_NMS_TOPK)
        if training:
            losses = rpn_losses(anchors.gt_labels,
                                anchors.encoded_gt_boxes(),
                                rpn_label_logits, rpn_box_logits)
        else:
            losses = []

        return BoxProposals(proposal_boxes), losses

    def roi_heads(self, image, features, proposals, targets):
        image_shape2d = tf.shape(image)[2:]
        featuremap = features[0]
        gt_boxes, gt_labels, *_ = targets
        if self.training:
            proposals = sample_fast_rcnn_targets(proposals.boxes, gt_boxes, gt_labels)
        boxes_on_featuremap =  proposals.boxes * (1.0 / RPN_ANCHOR_STRIDES)
        roi_resized = roi_align(featuremap, boxes_on_featuremap, 14)
        feature_fastrcnn = resnet_conv5(roi_resized, BACKBONE_RESNET_NUM_BLOCKS[-1])
        feature_gap = GobalAvgPooling('gap', feature_fastrcnn, data_format="channels_first")
        fastrcnn_label_logits, fastrcnn_box_logits = fastrcnn_outputs('fastrcnn',
                                                                      feature_gap,
                                                                      data_num_category)
        fastrcnn_head = FastRCNNHead(proposals,
                                     fastrcnn_box_logits,
                                     fastercnn_label_logits,
                                     gt_boxes,
                                     tf.constant(BBOX_REG_WEIGHTS, dtype=tf.float32))
        if self.training:
            all_losses = fastrcnn_head.losses()
            return all_losses
        else:
            decoded_boxes = fastrcnn_head.decoded_output_boxes()
            decoded_boxes = clip_boxes(decoded_boxes, image_shape2d, name="fastrcnn_all_boxes")
            label_scores = fastrcnn_head.output_scores(name="fastrcnn_all_scores")
            final_boxes, final_scores, final_labels = fastrcnn_predictions(
                decoded_boxes, label_scores, name_scope='output')
            return []
        
