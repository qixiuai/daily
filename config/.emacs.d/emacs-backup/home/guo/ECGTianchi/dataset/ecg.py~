import os
import pdb
import tensorflow as tf
import pandas as pd
import numpy as np
from tqdm import tqdm
from glob import glob
from absl import app
from absl import logging
from joblib import Parallel, delayed

data_dir = "/home/guo/ECGTianchi/data/"

def get_signals(sample_path):
    df = pd.read_table(sample_path, sep=" ")
    df["III"] = df["II"] - df["I"]
    df["aVR"] = -(df["I"] + df["II"]) / 2
    df["aVL"] = df["I"] - df["II"] / 2
    df["aVF"] = df["II"] - df["I"] / 2
    return df.values

def get_annotations(label_path):
    annotations = {}
    encoder = Encoder()
    with open(label_path) as file:
        for line in file:
            record = line.strip().split("\t")
            id = record[0]
            age = record[1]
            if age == "":
                age = 47
                age = 0.5
            else:
                age = int(age)
                age = (age - 47) / 50
            sex = record[2]
            is_male = 1 if sex == "MALE" else 0
            is_female = 1 if sex == "FEMALE" else 0
            labels = record[3:]
            label_ids = [0.1 for i in range(55)]
            for lb in labels:
                label_id = encoder.encode(lb)
                label_ids[label_id]= 0.9
            annotations[id] = (age, is_male, is_female, label_ids)
    return annotations

class Encoder(object):

    def __init__(self):
        kclass_path = data_dir + "hf_round1_arrythmia.txt"
        self._name_id = {}
        self._id_name = {}
        id = 0
        with open(kclass_path) as file:
            for line in file:
                name = line.strip()
                self._name_id[name] = id
                self._id_name[id] = name
                id += 1
                
    def encode(self, name):
        return self._name_id[name]

    def decode(self, id):
        return self._id_name[id]


class ECG(object):

    def __init__(self, mode="train"):
        self.mode = mode
        self.train_dir = data_dir + "train/"
        self.testa_dir = data_dir + "testA/"
        self.label_path_train = data_dir + "hf_round1_label.txt"
        self.label_path_testa = data_dir + "hf_round1_subA.txt"
        if mode == "train" or mode == "minival":
            self.data_dir = self.train_dir
            self.label_path = self.label_path_train
        else:
            self.data_dir = self.testa_dir
            self.label_path = self.label_path_testa

        self.annotations = self._extract_annotations()
        self.samples_data = self._extract_data()
        
    def _extract_data(self):
        sample_paths = [self.data_dir + sample_id for sample_id in self.samples]
        data = {}
        logging.info("loading samples")
        def _read_sample(sample_path):
            signals = get_signals(sample_path)
            sample_id = os.path.basename(sample_path)
            return (sample_id, signals)
        samples = Parallel(n_jobs=-1, verbose=1)(delayed(_read_sample)(sample_path) for sample_path in sample_paths)
        for sample in samples:
            id = sample[0]
            signals = sample[1]
            data[id] = signals
        return data

    def _extract_annotations(self):
        logging.info("loading annotations")
        np.random.seed(1)
        annotations = get_annotations(self.label_path)
        samples = list(annotations.keys())
        np.random.shuffle(samples)
        ind = int(len(samples) * 0.8)
        if self.mode == "train":
            self.samples = samples[:ind]
        elif self.mode == "minival":
            self.samples = samples[ind:]
        else:
            self.samples = samples
        return annotations

    def __call__(self):
        for sample in self.samples:
            data = self.samples_data[sample]
            anno = self.annotations[sample]
            sample = (data, anno[:-1], anno[-1])
            yield (sample,anno[-1])

def split_dataset(_):
    label_path = data_dir + "hf_round1_label.txt"
    annotations = get_annotations(label_path)
    samples = list(annotations.keys())
    np.random.shuffle(samples)
    num_samples = len(samples)
    ind = int(num_samples*0.7)
    train_samples = samples[:ind]
    valid_samples = samples[ind:]


def main(_):
    #encoder = Encoder()
    #get_annotations(data_dir + "hf_round1_label.txt")
    train = ECG(mode="train")
    dataset = tf.data.Dataset.from_generator(
        train,
        output_types=((tf.float32, tf.float32), tf.int64),
        output_shapes=(((5000, 12),(3,)), (55,)))
    dataset = dataset.batch(2)
    for sample in dataset:
        print(sample)
        break

if __name__ == "__main__":
    #app.run(split_dataset)
    app.run(main)
