

import os
import time
import random
import numpy as np
import tensorflow as tf

from glob import glob
from scipy.io import loadmat
from scipy.signal import medfilt
from ecg.ecgpeaks import findpeaks_in_ecg

import plotly.graph_objs as go
from plotly.offline import plot

import pdb

np.random.seed(2019)

ISRUC_DIR = "/home/guo/physio/database/isruc/ExtractedChannels/"

BAD = [
    "/home/guo/physio/database/isruc/ExtractedChannels/subgroupI-Extractedchannels/subject8.mat", 
    "/home/guo/physio/database/isruc/ExtractedChannels/subgroupI-Extractedchannels/subject40.mat",
]

def find_intervals(example):
    example = example.tolist()
    peak_indices, peak_values = findpeaks_in_ecg(example, fs=200)
    intervals =  np.diff(peak_indices)
    intervals = list(map(lambda x : x*5, intervals))
    #plot([go.Scatter(y=example, mode="lines", name="signal"),
    #      go.Scatter(x=peak_indices, y=peak_values, mode="markers", name="peak"),
    #])
    #time.sleep(2)
    return intervals

def spike_filter(intervals):
    intervals = np.asarray(intervals)
    intervals_movmean = medfilt(intervals, 301)
    intervals_diff = intervals - intervals_movmean
    intervals_diff_sorted = np.copy(np.abs(intervals_diff))
    intervals_diff_sorted.sort()
    num_intervals = len(intervals)
    mean_diff = intervals_diff_sorted[int(num_intervals*0.90)]
    #pdb.set_trace()
    #plot([go.Scatter(y=intervals_diff[:300], mode="lines+markers")])
    for ind in range(num_intervals):
        cur_diff = np.abs(intervals_diff[ind])
        if cur_diff >= 1.1 * mean_diff:
            intervals_diff[ind] = 0
    intervals_filter = intervals_movmean + intervals_diff
    #plot(go.Figure([go.Scatter(y=intervals[:300], mode="lines+markers", name="raw intervals"),
                    #go.Scatter(y=intervals_filter[:300], mode="lines+markers", name="filtered intervals"),
                    #go.Scatter(y=intervals_movmean[:300], mode="lines", name="move mean")],
                   #layout=go.Layout(yaxis=dict(range=[600,780]))))
    return intervals_filter


def generate_dataset_from_mats_to_tfrecord(mat_files, tfrecord_file, step_size):
    with tf.io.TFRecordWriter(tfrecord_file) as writer:
            for mat_file in mat_files:
                signal = loadmat(mat_file, variable_names=['X2'])['X2'].flatten()
                intervals = find_intervals(signal)
                intervals = spike_filter(intervals)
                num_intervals = len(intervals)
                num_example = int(num_intervals / step_size)
                for ind in range(num_example):
                    start = step_size * ind
                    end = step_size * (ind + 1)
                    intervals_example = intervals[start : end]
                    feature = tf.train.Feature(float_list=tf.train.FloatList(value=intervals_example))
                    example = tf.train.Example(features=tf.train.Features(feature={"interval": feature}))
                    writer.write(example.SerializeToString())


class HeartIsruc(object):

    def __init__(self, tmp_dir="/home/guo/physio/tmp_data/heart/", step_size=256):
        self.mat_files = glob(ISRUC_DIR + "**/*.mat", recursive=True)
        self.tmp_dir = tmp_dir
        self.step_size = step_size
        
    def generate_dataset(self):
        #basename = os.path.basename(mat_file)
        #subject = basename[:-4]
        #filename =  os.path.join(self.tmp_dir, subject + ".tfrecord")
        train_tfrecord = os.path.join(self.tmp_dir, "heart_train.tfrecords")
        dev_tfrecord = os.path.join(self.tmp_dir, "heart_dev.tfrecords")
        test_tfrecord = os.path.join(self.tmp_dir, "heart_test.tfrecords")

        random.shuffle(self.mat_files)
        num_mat_files = len(self.mat_files)
        num_train = int(num_mat_files*0.6)
        num_dev = int(num_mat_files*0.2)
        num_test = int(num_mat_files*0.2)
        train_mats = self.mat_files[:num_train]
        dev_mats = self.mat_files[num_train:num_train+num_dev]
        test_mats = self.mat_files[-num_test:]
        generate_dataset_from_mats_to_tfrecord(train_mats, train_tfrecord, self.step_size)
        generate_dataset_from_mats_to_tfrecord(dev_mats, dev_tfrecord, self.step_size)
        generate_dataset_from_mats_to_tfrecord(test_mats, test_tfrecord, self.step_size)

    def __call__(self, mode="train"):
        feature_descritption = {
            'interval' : tf.io.VarLenFeature(tf.float32),
        }
        def _parse_function(example_proto):
            example = tf.io.parse_single_example(example_proto, feature_descritption)
            interval = example['interval']
            return interval
        if mode == "train":
            tf_records_file = self.tmp_dir + "heart_train.tfrecords"
        elif mode == "valid":
            tf_records_file = self.tmp_dir + "heart_dev.tfrecords"
        elif mode == "test":
            tf_records_file = self.tmp_dir + "heart_test.tfrecords"
        else:
            raise Exception("illeagal mode in HeartIsruc")
        dataset = tf.data.TFRecordDataset([tf_records_file])
        dataset = dataset.map(_parse_function).map(tf.sparse.to_dense).map(lambda example: tf.reshape(example, [-1,1]))
        def add_noise(example):
            mask = np.asarray(np.random.uniform(0,1,256) > 0.9, dtype=np.int)
            var = np.random.randn(256)*10
            noise = np.asarray(mask*var, dtype=np.int).reshape(-1, 1)
            return example + noise
        dataset = dataset.map(lambda example : (add_noise(example), example))
        return dataset

    def test_interval(self):
        for mat_file in BAD:#self.mat_files:
            signal = loadmat(mat_file, variable_names=['X2'])['X2'].flatten()
            intervals = find_intervals(signal)
            plot([go.Scatter(y=intervals, mode="lines+markers", name="heart rates")], filename=mat_file)
            intervals = spike_filter(intervals)            
            #plot(go.Figure(data=[go.Scatter(y=intervals, mode="lines+markers")],
            #               layout=go.Layout(yaxis=dict(range=[450,1300]))), filename=mat_file)
            #time.sleep(1)
        
if __name__ == '__main__':
    heart_isruc = HeartIsruc()
    heart_isruc.generate_dataset()
    dataset = heart_isruc()
    #heart_isruc.test_interval()
    exit(0)
    for input, target in dataset.take(100):
        print(target.shape)
        plot([go.Scatter(y=input.numpy().flatten(), mode="lines+markers", name="input"),
              #go.Scatter(y=target.numpy().flatten(), mode="lines+markers", name="target"),
        ])
        time.sleep(1)

        
